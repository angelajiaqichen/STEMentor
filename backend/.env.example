# Environment configuration for STEMentor API

# Hugging Face Configuration
# Get your token from: https://huggingface.co/settings/tokens
# This is REQUIRED for the Inference API
HUGGINGFACE_TOKEN=your_huggingface_token_here

# Model Configuration (API-based, no local download needed)
# Using Hugging Face Inference API - models run on HF servers
# Recommended: meta-llama/Meta-Llama-3-8B-Instruct (fast and efficient)
LLAMA_MODEL=meta-llama/Meta-Llama-3-8B-Instruct

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=True

# CORS Configuration
ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000
